{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\"Functions for building the face recognition network.\r\n",
    "\"\"\"\r\n",
    "# MIT License\r\n",
    "# \r\n",
    "# Copyright (c) 2016 David Sandberg\r\n",
    "# \r\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\r\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\r\n",
    "# in the Software without restriction, including without limitation the rights\r\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n",
    "# copies of the Software, and to permit persons to whom the Software is\r\n",
    "# furnished to do so, subject to the following conditions:\r\n",
    "# \r\n",
    "# The above copyright notice and this permission notice shall be included in all\r\n",
    "# copies or substantial portions of the Software.\r\n",
    "# \r\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\n",
    "# SOFTWARE.\r\n",
    "\r\n",
    "# pylint: disable=missing-docstring\r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "import imageio\r\n",
    "import os\r\n",
    "from subprocess import Popen, PIPE\r\n",
    "import tensorflow.compat.v1 as tf\r\n",
    "\r\n",
    "from tensorflow.python.framework import ops\r\n",
    "import numpy as np\r\n",
    "from scipy import misc\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "from scipy import interpolate\r\n",
    "from tensorflow.python.training import training\r\n",
    "import random\r\n",
    "import re\r\n",
    "from tensorflow.python.platform import gfile\r\n",
    "\r\n",
    "def triplet_loss(anchor, positive, negative, alpha):\r\n",
    "    \"\"\"Calculate the triplet loss according to the FaceNet paper\r\n",
    "    \r\n",
    "    Args:\r\n",
    "      anchor: the embeddings for the anchor images.\r\n",
    "      positive: the embeddings for the positive images.\r\n",
    "      negative: the embeddings for the negative images.\r\n",
    "  \r\n",
    "    Returns:\r\n",
    "      the triplet loss according to the FaceNet paper as a float tensor.\r\n",
    "    \"\"\"\r\n",
    "    with tf.variable_scope('triplet_loss'):\r\n",
    "        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\r\n",
    "        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\r\n",
    "        \r\n",
    "        basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha)\r\n",
    "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\r\n",
    "      \r\n",
    "    return loss\r\n",
    "  \r\n",
    "def decov_loss(xs):\r\n",
    "    \"\"\"Decov loss as described in https://arxiv.org/pdf/1511.06068.pdf\r\n",
    "    'Reducing Overfitting In Deep Networks by Decorrelating Representation'\r\n",
    "    \"\"\"\r\n",
    "    x = tf.reshape(xs, [int(xs.get_shape()[0]), -1])\r\n",
    "    m = tf.reduce_mean(x, 0, True)\r\n",
    "    z = tf.expand_dims(x-m, 2)\r\n",
    "    corr = tf.reduce_mean(tf.matmul(z, tf.transpose(z, perm=[0,2,1])), 0)\r\n",
    "    corr_frob_sqr = tf.reduce_sum(tf.square(corr))\r\n",
    "    corr_diag_sqr = tf.reduce_sum(tf.square(tf.diag_part(corr)))\r\n",
    "    loss = 0.5*(corr_frob_sqr - corr_diag_sqr)\r\n",
    "    return loss \r\n",
    "  \r\n",
    "def center_loss(features, label, alfa, nrof_classes):\r\n",
    "    \"\"\"Center loss based on the paper \"A Discriminative Feature Learning Approach for Deep Face Recognition\"\r\n",
    "       (http://ydwen.github.io/papers/WenECCV16.pdf)\r\n",
    "    \"\"\"\r\n",
    "    nrof_features = features.get_shape()[1]\r\n",
    "    centers = tf.get_variable('centers', [nrof_classes, nrof_features], dtype=tf.float32,\r\n",
    "        initializer=tf.constant_initializer(0), trainable=False)\r\n",
    "    label = tf.reshape(label, [-1])\r\n",
    "    centers_batch = tf.gather(centers, label)\r\n",
    "    diff = (1 - alfa) * (centers_batch - features)\r\n",
    "    centers = tf.scatter_sub(centers, label, diff)\r\n",
    "    loss = tf.reduce_mean(tf.square(features - centers_batch))\r\n",
    "    return loss, centers\r\n",
    "\r\n",
    "def get_image_paths_and_labels(dataset):\r\n",
    "    image_paths_flat = []\r\n",
    "    labels_flat = []\r\n",
    "    for i in range(len(dataset)):\r\n",
    "        image_paths_flat += dataset[i].image_paths\r\n",
    "        labels_flat += [i] * len(dataset[i].image_paths)\r\n",
    "    return image_paths_flat, labels_flat\r\n",
    "\r\n",
    "def shuffle_examples(image_paths, labels):\r\n",
    "    shuffle_list = list(zip(image_paths, labels))\r\n",
    "    random.shuffle(shuffle_list)\r\n",
    "    image_paths_shuff, labels_shuff = zip(*shuffle_list)\r\n",
    "    return image_paths_shuff, labels_shuff\r\n",
    "\r\n",
    "def read_images_from_disk(input_queue):\r\n",
    "    \"\"\"Consumes a single filename and label as a ' '-delimited string.\r\n",
    "    Args:\r\n",
    "      filename_and_label_tensor: A scalar string tensor.\r\n",
    "    Returns:\r\n",
    "      Two tensors: the decoded image, and the string label.\r\n",
    "    \"\"\"\r\n",
    "    label = input_queue[1]\r\n",
    "    file_contents = tf.read_file(input_queue[0])\r\n",
    "    example = tf.image.decode_png(file_contents, channels=3)\r\n",
    "    return example, label\r\n",
    "  \r\n",
    "def random_rotate_image(image):\r\n",
    "    angle = np.random.uniform(low=-10.0, high=10.0)\r\n",
    "    return misc.imrotate(image, angle, 'bicubic')\r\n",
    "  \r\n",
    "def read_and_augment_data(image_list, label_list, image_size, batch_size, max_nrof_epochs, \r\n",
    "        random_crop, random_flip, random_rotate, nrof_preprocess_threads, shuffle=True):\r\n",
    "    \r\n",
    "    images = ops.convert_to_tensor(image_list, dtype=tf.string)\r\n",
    "    labels = ops.convert_to_tensor(label_list, dtype=tf.int32)\r\n",
    "    \r\n",
    "    # Makes an input queue\r\n",
    "    input_queue = tf.train.slice_input_producer([images, labels],\r\n",
    "        num_epochs=max_nrof_epochs, shuffle=shuffle)\r\n",
    "\r\n",
    "    images_and_labels = []\r\n",
    "    for _ in range(nrof_preprocess_threads):\r\n",
    "        image, label = read_images_from_disk(input_queue)\r\n",
    "        if random_rotate:\r\n",
    "            image = tf.py_func(random_rotate_image, [image], tf.uint8)\r\n",
    "        if random_crop:\r\n",
    "            image = tf.random_crop(image, [image_size, image_size, 3])\r\n",
    "        else:\r\n",
    "            image = tf.image.resize_image_with_crop_or_pad(image, image_size, image_size)\r\n",
    "        if random_flip:\r\n",
    "            image = tf.image.random_flip_left_right(image)\r\n",
    "        #pylint: disable=no-member\r\n",
    "        image.set_shape((image_size, image_size, 3))\r\n",
    "        image = tf.image.per_image_standardization(image)\r\n",
    "        images_and_labels.append([image, label])\r\n",
    "\r\n",
    "    image_batch, label_batch = tf.train.batch_join(\r\n",
    "        images_and_labels, batch_size=batch_size,\r\n",
    "        capacity=4 * nrof_preprocess_threads * batch_size,\r\n",
    "        allow_smaller_final_batch=True)\r\n",
    "  \r\n",
    "    return image_batch, label_batch\r\n",
    "  \r\n",
    "def _add_loss_summaries(total_loss):\r\n",
    "    \"\"\"Add summaries for losses.\r\n",
    "  \r\n",
    "    Generates moving average for all losses and associated summaries for\r\n",
    "    visualizing the performance of the network.\r\n",
    "  \r\n",
    "    Args:\r\n",
    "      total_loss: Total loss from loss().\r\n",
    "    Returns:\r\n",
    "      loss_averages_op: op for generating moving averages of losses.\r\n",
    "    \"\"\"\r\n",
    "    # Compute the moving average of all individual losses and the total loss.\r\n",
    "    loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\r\n",
    "    losses = tf.get_collection('losses')\r\n",
    "    loss_averages_op = loss_averages.apply(losses + [total_loss])\r\n",
    "  \r\n",
    "    # Attach a scalar summmary to all individual losses and the total loss; do the\r\n",
    "    # same for the averaged version of the losses.\r\n",
    "    for l in losses + [total_loss]:\r\n",
    "        # Name each loss as '(raw)' and name the moving average version of the loss\r\n",
    "        # as the original loss name.\r\n",
    "        tf.summary.scalar(l.op.name +' (raw)', l)\r\n",
    "        tf.summary.scalar(l.op.name, loss_averages.average(l))\r\n",
    "  \r\n",
    "    return loss_averages_op\r\n",
    "\r\n",
    "def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\r\n",
    "    # Generate moving averages of all losses and associated summaries.\r\n",
    "    loss_averages_op = _add_loss_summaries(total_loss)\r\n",
    "\r\n",
    "    # Compute gradients.\r\n",
    "    with tf.control_dependencies([loss_averages_op]):\r\n",
    "        if optimizer=='ADAGRAD':\r\n",
    "            opt = tf.train.AdagradOptimizer(learning_rate)\r\n",
    "        elif optimizer=='ADADELTA':\r\n",
    "            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\r\n",
    "        elif optimizer=='ADAM':\r\n",
    "            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\r\n",
    "        elif optimizer=='RMSPROP':\r\n",
    "            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\r\n",
    "        elif optimizer=='MOM':\r\n",
    "            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\r\n",
    "        else:\r\n",
    "            raise ValueError('Invalid optimization algorithm')\r\n",
    "    \r\n",
    "        grads = opt.compute_gradients(total_loss, update_gradient_vars)\r\n",
    "        \r\n",
    "    # Apply gradients.\r\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\r\n",
    "  \r\n",
    "    # Add histograms for trainable variables.\r\n",
    "    if log_histograms:\r\n",
    "        for var in tf.trainable_variables():\r\n",
    "            tf.summary.histogram(var.op.name, var)\r\n",
    "   \r\n",
    "    # Add histograms for gradients.\r\n",
    "    if log_histograms:\r\n",
    "        for grad, var in grads:\r\n",
    "            if grad is not None:\r\n",
    "                tf.summary.histogram(var.op.name + '/gradients', grad)\r\n",
    "  \r\n",
    "    # Track the moving averages of all trainable variables.\r\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\r\n",
    "        moving_average_decay, global_step)\r\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\r\n",
    "  \r\n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\r\n",
    "        train_op = tf.no_op(name='train')\r\n",
    "  \r\n",
    "    return train_op\r\n",
    "\r\n",
    "def prewhiten(x):\r\n",
    "    mean = np.mean(x)\r\n",
    "    std = np.std(x)\r\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\r\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\r\n",
    "    return y  \r\n",
    "\r\n",
    "def crop(image, random_crop, image_size):\r\n",
    "    if image.shape[1]>image_size:\r\n",
    "        sz1 = int(image.shape[1]//2)\r\n",
    "        sz2 = int(image_size//2)\r\n",
    "        if random_crop:\r\n",
    "            diff = sz1-sz2\r\n",
    "            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\r\n",
    "        else:\r\n",
    "            (h, v) = (0,0)\r\n",
    "        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\r\n",
    "    return image\r\n",
    "  \r\n",
    "def flip(image, random_flip):\r\n",
    "    if random_flip and np.random.choice([True, False]):\r\n",
    "        image = np.fliplr(image)\r\n",
    "    return image\r\n",
    "\r\n",
    "def to_rgb(img):\r\n",
    "    w, h = img.shape\r\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\r\n",
    "    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\r\n",
    "    return ret\r\n",
    "  \r\n",
    "def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\r\n",
    "    nrof_samples = len(image_paths)\r\n",
    "    images = np.zeros((nrof_samples, image_size, image_size, 3))\r\n",
    "    for i in range(nrof_samples):\r\n",
    "        img = imageio.imread(image_paths[i])\r\n",
    "        if img.ndim == 2:\r\n",
    "            img = to_rgb(img)\r\n",
    "        if do_prewhiten:\r\n",
    "            img = prewhiten(img)\r\n",
    "        img = crop(img, do_random_crop, image_size)\r\n",
    "        img = flip(img, do_random_flip)\r\n",
    "        images[i,:,:,:] = img\r\n",
    "    return images\r\n",
    "\r\n",
    "def get_label_batch(label_data, batch_size, batch_index):\r\n",
    "    nrof_examples = np.size(label_data, 0)\r\n",
    "    j = batch_index*batch_size % nrof_examples\r\n",
    "    if j+batch_size<=nrof_examples:\r\n",
    "        batch = label_data[j:j+batch_size]\r\n",
    "    else:\r\n",
    "        x1 = label_data[j:nrof_examples]\r\n",
    "        x2 = label_data[0:nrof_examples-j]\r\n",
    "        batch = np.vstack([x1,x2])\r\n",
    "    batch_int = batch.astype(np.int64)\r\n",
    "    return batch_int\r\n",
    "\r\n",
    "def get_batch(image_data, batch_size, batch_index):\r\n",
    "    nrof_examples = np.size(image_data, 0)\r\n",
    "    j = batch_index*batch_size % nrof_examples\r\n",
    "    if j+batch_size<=nrof_examples:\r\n",
    "        batch = image_data[j:j+batch_size,:,:,:]\r\n",
    "    else:\r\n",
    "        x1 = image_data[j:nrof_examples,:,:,:]\r\n",
    "        x2 = image_data[0:nrof_examples-j,:,:,:]\r\n",
    "        batch = np.vstack([x1,x2])\r\n",
    "    batch_float = batch.astype(np.float32)\r\n",
    "    return batch_float\r\n",
    "\r\n",
    "def get_triplet_batch(triplets, batch_index, batch_size):\r\n",
    "    ax, px, nx = triplets\r\n",
    "    a = get_batch(ax, int(batch_size/3), batch_index)\r\n",
    "    p = get_batch(px, int(batch_size/3), batch_index)\r\n",
    "    n = get_batch(nx, int(batch_size/3), batch_index)\r\n",
    "    batch = np.vstack([a, p, n])\r\n",
    "    return batch\r\n",
    "\r\n",
    "def get_learning_rate_from_file(filename, epoch):\r\n",
    "    with open(filename, 'r') as f:\r\n",
    "        for line in f.readlines():\r\n",
    "            line = line.split('#', 1)[0]\r\n",
    "            if line:\r\n",
    "                par = line.strip().split(':')\r\n",
    "                e = int(par[0])\r\n",
    "                lr = float(par[1])\r\n",
    "                if e <= epoch:\r\n",
    "                    learning_rate = lr\r\n",
    "                else:\r\n",
    "                    return learning_rate\r\n",
    "\r\n",
    "class ImageClass():\r\n",
    "    \"Stores the paths to images for a given class\"\r\n",
    "    def __init__(self, name, image_paths):\r\n",
    "        self.name = name\r\n",
    "        self.image_paths = image_paths\r\n",
    "  \r\n",
    "    def __str__(self):\r\n",
    "        return self.name + ', ' + str(len(self.image_paths)) + ' images'\r\n",
    "  \r\n",
    "    def __len__(self):\r\n",
    "        return len(self.image_paths)\r\n",
    "  \r\n",
    "def get_dataset(paths, has_class_directories=True):\r\n",
    "    dataset = []\r\n",
    "    for path in paths.split(':'):\r\n",
    "        path_exp = os.path.expanduser(path)\r\n",
    "        classes = os.listdir(path_exp)\r\n",
    "        classes.sort()\r\n",
    "        nrof_classes = len(classes)\r\n",
    "        for i in range(nrof_classes):\r\n",
    "            class_name = classes[i]\r\n",
    "            facedir = os.path.join(path_exp, class_name)\r\n",
    "            image_paths = get_image_paths(facedir)\r\n",
    "            dataset.append(ImageClass(class_name, image_paths))\r\n",
    "  \r\n",
    "    return dataset\r\n",
    "\r\n",
    "def get_image_paths(facedir):\r\n",
    "    image_paths = []\r\n",
    "    if os.path.isdir(facedir):\r\n",
    "        images = os.listdir(facedir)\r\n",
    "        image_paths = [os.path.join(facedir,img) for img in images]\r\n",
    "    return image_paths\r\n",
    "  \r\n",
    "def split_dataset(dataset, split_ratio, mode):\r\n",
    "    if mode=='SPLIT_CLASSES':\r\n",
    "        nrof_classes = len(dataset)\r\n",
    "        class_indices = np.arange(nrof_classes)\r\n",
    "        np.random.shuffle(class_indices)\r\n",
    "        split = int(round(nrof_classes*split_ratio))\r\n",
    "        train_set = [dataset[i] for i in class_indices[0:split]]\r\n",
    "        test_set = [dataset[i] for i in class_indices[split:-1]]\r\n",
    "    elif mode=='SPLIT_IMAGES':\r\n",
    "        train_set = []\r\n",
    "        test_set = []\r\n",
    "        min_nrof_images = 2\r\n",
    "        for cls in dataset:\r\n",
    "            paths = cls.image_paths\r\n",
    "            np.random.shuffle(paths)\r\n",
    "            split = int(round(len(paths)*split_ratio))\r\n",
    "            if split<min_nrof_images:\r\n",
    "                continue  # Not enough images for test set. Skip class...\r\n",
    "            train_set.append(ImageClass(cls.name, paths[0:split]))\r\n",
    "            test_set.append(ImageClass(cls.name, paths[split:-1]))\r\n",
    "    else:\r\n",
    "        raise ValueError('Invalid train/test split mode \"%s\"' % mode)\r\n",
    "    return train_set, test_set\r\n",
    "\r\n",
    "def load_model(model):\r\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\r\n",
    "    #  or if it is a protobuf file with a frozen graph\r\n",
    "    model_exp = os.path.expanduser(model)\r\n",
    "    if (os.path.isfile(model_exp)):\r\n",
    "        print('Model filename: %s' % model_exp)\r\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\r\n",
    "            graph_def = tf.GraphDef()\r\n",
    "            graph_def.ParseFromString(f.read())\r\n",
    "            tf.import_graph_def(graph_def, name='')\r\n",
    "    else:\r\n",
    "        print('Model directory: %s' % model_exp)\r\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\r\n",
    "        \r\n",
    "        print('Metagraph file: %s' % meta_file)\r\n",
    "        print('Checkpoint file: %s' % ckpt_file)\r\n",
    "      \r\n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file))\r\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\r\n",
    "    \r\n",
    "def get_model_filenames(model_dir):\r\n",
    "    files = os.listdir(model_dir)\r\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\r\n",
    "    if len(meta_files)==0:\r\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\r\n",
    "    elif len(meta_files)>1:\r\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\r\n",
    "    meta_file = meta_files[0]\r\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\r\n",
    "    max_step = -1\r\n",
    "    for f in files:\r\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\r\n",
    "        if step_str is not None and len(step_str.groups())>=2:\r\n",
    "            step = int(step_str.groups()[1])\r\n",
    "            if step > max_step:\r\n",
    "                max_step = step\r\n",
    "                ckpt_file = step_str.groups()[0]\r\n",
    "    return meta_file, ckpt_file\r\n",
    "\r\n",
    "def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10):\r\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\r\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\r\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\r\n",
    "    nrof_thresholds = len(thresholds)\r\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\r\n",
    "    \r\n",
    "    tprs = np.zeros((nrof_folds,nrof_thresholds))\r\n",
    "    fprs = np.zeros((nrof_folds,nrof_thresholds))\r\n",
    "    accuracy = np.zeros((nrof_folds))\r\n",
    "    \r\n",
    "    diff = np.subtract(embeddings1, embeddings2)\r\n",
    "    dist = np.sum(np.square(diff),1)\r\n",
    "    indices = np.arange(nrof_pairs)\r\n",
    "    \r\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\r\n",
    "        \r\n",
    "        # Find the best threshold for the fold\r\n",
    "        acc_train = np.zeros((nrof_thresholds))\r\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\r\n",
    "            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\r\n",
    "        best_threshold_index = np.argmax(acc_train)\r\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\r\n",
    "            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\r\n",
    "        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\r\n",
    "          \r\n",
    "        tpr = np.mean(tprs,0)\r\n",
    "        fpr = np.mean(fprs,0)\r\n",
    "    return tpr, fpr, accuracy\r\n",
    "\r\n",
    "def calculate_accuracy(threshold, dist, actual_issame):\r\n",
    "    predict_issame = np.less(dist, threshold)\r\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\r\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\r\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\r\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\r\n",
    "  \r\n",
    "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\r\n",
    "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\r\n",
    "    acc = float(tp+tn)/dist.size\r\n",
    "    return tpr, fpr, acc\r\n",
    "\r\n",
    "\r\n",
    "  \r\n",
    "def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10):\r\n",
    "    assert(embeddings1.shape[0] == embeddings2.shape[0])\r\n",
    "    assert(embeddings1.shape[1] == embeddings2.shape[1])\r\n",
    "    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\r\n",
    "    nrof_thresholds = len(thresholds)\r\n",
    "    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\r\n",
    "    \r\n",
    "    val = np.zeros(nrof_folds)\r\n",
    "    far = np.zeros(nrof_folds)\r\n",
    "    \r\n",
    "    diff = np.subtract(embeddings1, embeddings2)\r\n",
    "    dist = np.sum(np.square(diff),1)\r\n",
    "    indices = np.arange(nrof_pairs)\r\n",
    "    \r\n",
    "    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\r\n",
    "      \r\n",
    "        # Find the threshold that gives FAR = far_target\r\n",
    "        far_train = np.zeros(nrof_thresholds)\r\n",
    "        for threshold_idx, threshold in enumerate(thresholds):\r\n",
    "            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\r\n",
    "        if np.max(far_train)>=far_target:\r\n",
    "            f = interpolate.interp1d(far_train, thresholds, kind='slinear')\r\n",
    "            threshold = f(far_target)\r\n",
    "        else:\r\n",
    "            threshold = 0.0\r\n",
    "    \r\n",
    "        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\r\n",
    "  \r\n",
    "    val_mean = np.mean(val)\r\n",
    "    far_mean = np.mean(far)\r\n",
    "    val_std = np.std(val)\r\n",
    "    return val_mean, val_std, far_mean\r\n",
    "\r\n",
    "\r\n",
    "def calculate_val_far(threshold, dist, actual_issame):\r\n",
    "    predict_issame = np.less(dist, threshold)\r\n",
    "    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\r\n",
    "    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\r\n",
    "    n_same = np.sum(actual_issame)\r\n",
    "    n_diff = np.sum(np.logical_not(actual_issame))\r\n",
    "    val = float(true_accept) / float(n_same)\r\n",
    "    far = float(false_accept) / float(n_diff)\r\n",
    "    return val, far\r\n",
    "\r\n",
    "def store_revision_info(src_path, output_dir, arg_string):\r\n",
    "  \r\n",
    "    # Get git hash\r\n",
    "    gitproc = Popen(['git', 'rev-parse', 'HEAD'], stdout = PIPE, cwd=src_path)\r\n",
    "    (stdout, _) = gitproc.communicate()\r\n",
    "    git_hash = stdout.strip()\r\n",
    "  \r\n",
    "    # Get local changes\r\n",
    "    gitproc = Popen(['git', 'diff', 'HEAD'], stdout = PIPE, cwd=src_path)\r\n",
    "    (stdout, _) = gitproc.communicate()\r\n",
    "    git_diff = stdout.strip()\r\n",
    "    \r\n",
    "    # Store a text file in the log directory\r\n",
    "    rev_info_filename = os.path.join(output_dir, 'revision_info.txt')\r\n",
    "    with open(rev_info_filename, \"w\") as text_file:\r\n",
    "        text_file.write('arguments: %s\\n--------------------\\n' % arg_string)\r\n",
    "        text_file.write('git hash: %s\\n--------------------\\n' % git_hash)\r\n",
    "        text_file.write('%s' % git_diff)\r\n",
    "\r\n",
    "def list_variables(filename):\r\n",
    "    reader = training.NewCheckpointReader(filename)\r\n",
    "    variable_map = reader.get_variable_to_shape_map()\r\n",
    "    names = sorted(variable_map.keys())\r\n",
    "    return names\r\n",
    "\r\n",
    "def put_images_on_grid(images, shape=(16,8)):\r\n",
    "    nrof_images = images.shape[0]\r\n",
    "    img_size = images.shape[1]\r\n",
    "    bw = 3\r\n",
    "    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]*(img_size+bw)+bw, 3), np.float32)\r\n",
    "    for i in range(shape[1]):\r\n",
    "        x_start = i*(img_size+bw)+bw\r\n",
    "        for j in range(shape[0]):\r\n",
    "            img_index = i*shape[0]+j\r\n",
    "            if img_index>=nrof_images:\r\n",
    "                break\r\n",
    "            y_start = j*(img_size+bw)+bw\r\n",
    "            img[x_start:x_start+img_size, y_start:y_start+img_size, :] = images[img_index, :, :, :]\r\n",
    "        if img_index>=nrof_images:\r\n",
    "            break\r\n",
    "    return img\r\n",
    "\r\n",
    "def write_arguments_to_file(args, filename):\r\n",
    "    with open(filename, 'w') as f:\r\n",
    "        for key, value in vars(args).iteritems():\r\n",
    "            f.write('%s: %s\\n' % (key, str(value)))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "from PIL import Image\r\n",
    "import os\r\n",
    "import tensorflow.compat.v1 as tf\r\n",
    "import numpy as np\r\n",
    "import facenet\r\n",
    "import detect_face\r\n",
    "import imageio\r\n",
    "class preprocesses:\r\n",
    "    def __init__(self, input_datadir, output_datadir):\r\n",
    "        self.input_datadir = input_datadir\r\n",
    "        self.output_datadir = output_datadir\r\n",
    "\r\n",
    "    def collect_data(self):\r\n",
    "        output_dir = os.path.expanduser(self.output_datadir)\r\n",
    "        if not os.path.exists(output_dir):\r\n",
    "            os.makedirs(output_dir)\r\n",
    "\r\n",
    "        dataset = facenet.get_dataset(self.input_datadir)\r\n",
    "        with tf.Graph().as_default():\r\n",
    "            gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\r\n",
    "            sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\r\n",
    "            with sess.as_default():\r\n",
    "                pnet, rnet, onet = detect_face.create_mtcnn(sess, './npy')\r\n",
    "\r\n",
    "        minsize = 20  # minimum size of face\r\n",
    "        threshold = [0.6, 0.7, 0.7]  # three steps's threshold\r\n",
    "        factor = 0.709  # scale factor\r\n",
    "        margin = 44\r\n",
    "        image_size = 182\r\n",
    "\r\n",
    "        # Add a random key to the filename to allow alignment using multiple processes\r\n",
    "        random_key = np.random.randint(0, high=99999)\r\n",
    "        bounding_boxes_filename = os.path.join(output_dir, 'bounding_boxes_%05d.txt' % random_key)\r\n",
    "\r\n",
    "        with open(bounding_boxes_filename, \"w\") as text_file:\r\n",
    "            nrof_images_total = 0\r\n",
    "            nrof_successfully_aligned = 0\r\n",
    "            for cls in dataset:\r\n",
    "                output_class_dir = os.path.join(output_dir, cls.name)\r\n",
    "                if not os.path.exists(output_class_dir):\r\n",
    "                    os.makedirs(output_class_dir)\r\n",
    "                for image_path in cls.image_paths:\r\n",
    "                    nrof_images_total += 1\r\n",
    "                    filename = os.path.splitext(os.path.split(image_path)[1])[0]\r\n",
    "                    output_filename = os.path.join(output_class_dir, filename + '.png')\r\n",
    "                    print(\"Image: %s\" % image_path)\r\n",
    "                    if not os.path.exists(output_filename):\r\n",
    "                        try:\r\n",
    "                            img = imageio.imread(image_path)\r\n",
    "                        except (IOError, ValueError, IndexError) as e:\r\n",
    "                            errorMessage = '{}: {}'.format(image_path, e)\r\n",
    "                            print(errorMessage)\r\n",
    "                        else:\r\n",
    "                            if img.ndim < 2:\r\n",
    "                                print('Unable to align \"%s\"' % image_path)\r\n",
    "                                text_file.write('%s\\n' % (output_filename))\r\n",
    "                                continue\r\n",
    "                            if img.ndim == 2:\r\n",
    "                                img = facenet.to_rgb(img)\r\n",
    "                                print('to_rgb data dimension: ', img.ndim)\r\n",
    "                            img = img[:, :, 0:3]\r\n",
    "\r\n",
    "                            bounding_boxes, _ = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold,\r\n",
    "                                                                        factor)\r\n",
    "                            nrof_faces = bounding_boxes.shape[0]\r\n",
    "                            print('No of Detected Face: %d' % nrof_faces)\r\n",
    "                            if nrof_faces > 0:\r\n",
    "                                det = bounding_boxes[:, 0:4]\r\n",
    "                                img_size = np.asarray(img.shape)[0:2]\r\n",
    "                                if nrof_faces > 1:\r\n",
    "                                    bounding_box_size = (det[:, 2] - det[:, 0]) * (det[:, 3] - det[:, 1])\r\n",
    "                                    img_center = img_size / 2\r\n",
    "                                    offsets = np.vstack([(det[:, 0] + det[:, 2]) / 2 - img_center[1],\r\n",
    "                                                         (det[:, 1] + det[:, 3]) / 2 - img_center[0]])\r\n",
    "                                    offset_dist_squared = np.sum(np.power(offsets, 2.0), 0)\r\n",
    "                                    index = np.argmax(\r\n",
    "                                        bounding_box_size - offset_dist_squared * 2.0)  # some extra weight on the centering\r\n",
    "                                    det = det[index, :]\r\n",
    "                                det = np.squeeze(det)\r\n",
    "                                bb_temp = np.zeros(4, dtype=np.int32)\r\n",
    "\r\n",
    "                                bb_temp[0] = det[0]\r\n",
    "                                bb_temp[1] = det[1]\r\n",
    "                                bb_temp[2] = det[2]\r\n",
    "                                bb_temp[3] = det[3]\r\n",
    "\r\n",
    "                                cropped_temp = img[bb_temp[1]:bb_temp[3], bb_temp[0]:bb_temp[2], :]\r\n",
    "                                #scaled_temp = misc.imresize(cropped_temp, (image_size, image_size), interp='bilinear')\r\n",
    "                                scaled_temp =np.array(Image.fromarray(cropped_temp).resize((image_size, image_size)))\r\n",
    "                                nrof_successfully_aligned += 1\r\n",
    "                                imageio.imwrite(output_filename, scaled_temp)\r\n",
    "                                text_file.write('%s %d %d %d %d\\n' % (\r\n",
    "                                output_filename, bb_temp[0], bb_temp[1], bb_temp[2], bb_temp[3]))\r\n",
    "                            else:\r\n",
    "                                print('Unable to align \"%s\"' % image_path)\r\n",
    "                                text_file.write('%s\\n' % (output_filename))\r\n",
    "\r\n",
    "        return (nrof_images_total,nrof_successfully_aligned)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from preprocess import preprocesses\r\n",
    "\r\n",
    "input_datadir = './train_img'\r\n",
    "output_datadir = './pre_img'\r\n",
    "\r\n",
    "obj=preprocesses(input_datadir,output_datadir)\r\n",
    "nrof_images_total,nrof_successfully_aligned=obj.collect_data()\r\n",
    "\r\n",
    "print('Total number of images: %d' % nrof_images_total)\r\n",
    "print('Number of successfully aligned images: %d' % nrof_successfully_aligned)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\amena\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\amena\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\Users\\amena\\OneDrive\\Bureau\\final demo\\Facenet-Real-time-face-recognition-using-deep-learning-Tensorflow\\detect_face.py:213: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_1.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_10.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_11.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_12.jpeg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_13.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_14.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_15.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_16.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_17.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_18.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_19.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_2.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_20.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_21.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_22.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_23.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_24.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_25.png\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_26.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_27.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_28.jpeg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_29.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_3.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_30.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_32.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_33.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_34.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_34.png\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_35.jpeg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_35.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_36.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_37.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_38.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_39.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_4.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_40.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_41.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_42.jpg\n",
      "./train_img\\Akshay Kumar\\ActiOn_42.jpg: Could not find a format to read the specified file in single-image mode\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_43.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_44.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_45.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_46.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_47.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_48.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_49.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_5.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_6.jpeg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_8.jpg\n",
      "Image: ./train_img\\Akshay Kumar\\ActiOn_9.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_1.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_10.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_11.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_12.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_13.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_14.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_15.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_17.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_18.jpeg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_19.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_2.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_20.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_21.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_22.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_23.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_24.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_25.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_26.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_27.jpeg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_28.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_29.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_3.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_30.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_31.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_32.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_33.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_34.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_35.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_36.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_37.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_39.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_4.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_40.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_41.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_42.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_43.jpeg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_43.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_5.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_7.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_8.jpg\n",
      "Image: ./train_img\\Nawazuddin Siddiqui\\ActiOn_9.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_1.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_10.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_11.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_12.jpeg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_13.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_15.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_16.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_17.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_19.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_2.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_20.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_21.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_22.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_23.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_24.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_25.cms\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_26.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_27.png\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_28.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_29.jpeg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_3.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_30.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_31.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_32.jpeg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_33.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_34.jpeg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_35.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_36.jpeg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_37.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_38.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_39.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_4.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_41.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_42.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_43.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_44.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_45.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_46.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_47.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_48.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_5.cms\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_6.png\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_7.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_8.jpg\n",
      "Image: ./train_img\\Salman Khan\\ActiOn_9.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_1.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_10.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_11.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_12.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_13.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_14.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_15.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_16.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_17.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_18.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_19.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_2.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_20.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_21.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_23.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_24.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_25.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_26.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_27.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_28.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_29.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_3.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_30.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_31.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_32.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_33.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_35.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_36.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_37.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_38.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_39.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_4.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_40.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_41.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_42.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_43.jpeg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_44.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_45.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_46.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_48.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_49.cms\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_49.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_5.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_50.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_51.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_6.cms\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_7.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_8.jpg\n",
      "Image: ./train_img\\Shahrukh Khan\\ActiOn_9.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_1.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_10.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_12.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_13.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_14.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_15.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_16.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_17.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_18.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_19.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_2.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_23.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_24.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_25.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_26.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_28.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_29.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_3.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_30.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_31.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_32.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_33.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_35.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_37.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_38.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_39.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_4.jpeg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_42.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_44.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_46.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_48.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_5.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_50.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_51.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_52.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_54.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_57.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_6.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_7.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_8.jpg\n",
      "Image: ./train_img\\Sunil Shetty\\ActiOn_9.png\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_1.jpeg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_10.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_11.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_12.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_13.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_14.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_15.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_16.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_17.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_18.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_2.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_20.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_21.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_22.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_23.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_24.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_25.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_29.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_3.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_31.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_32.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_34.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_35.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_36.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_38.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_39.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_4.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_40.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_41.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_42.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_43.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_45.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_46.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_48.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_49.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_5.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_50.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_51.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_52.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_54.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_56.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_57.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_59.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_60.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_61.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_62.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_63.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_67.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_7.jpg\n",
      "Image: ./train_img\\Sunny Deol\\ActiOn_9.jpg\n",
      "Image: ./train_img\\amenallah\\10259172_1666643040279726_4727929446229385879_o.jpg\n",
      "Image: ./train_img\\amenallah\\10373521_1667919080152122_1780904784811548822_n.jpg\n",
      "Image: ./train_img\\amenallah\\11221640_1653455341598496_4768462622820545103_n.jpg\n",
      "No of Detected Face: 0\n",
      "Unable to align \"./train_img\\amenallah\\11221640_1653455341598496_4768462622820545103_n.jpg\"\n",
      "Image: ./train_img\\amenallah\\12047108_1638969763047054_2046304835208570027_n.jpg\n",
      "Image: ./train_img\\amenallah\\12096548_1646357302308300_5880367349024775117_n.jpg\n",
      "Image: ./train_img\\amenallah\\12187838_1648867792057251_5081947015630262049_n.jpg\n",
      "Image: ./train_img\\amenallah\\12193556_1652115198399177_7780302603073254435_n.jpg\n",
      "Image: ./train_img\\amenallah\\13055408_1715734752037221_900984510515416316_n.jpg\n",
      "Image: ./train_img\\amenallah\\1604917563754.jpg\n",
      "Image: ./train_img\\amenallah\\16473356_1859809294296432_9177656772783600863_n.jpg\n",
      "Image: ./train_img\\amenallah\\171469169_2926037524340265_4986770951589523223_n.jpg\n",
      "Image: ./train_img\\amenallah\\17309567_1879180442359317_3705449250180461443_n.jpg\n",
      "Image: ./train_img\\amenallah\\17904282_1897823170495044_3084744340270456533_n.jpg\n",
      "Image: ./train_img\\amenallah\\1935613_1663918167218880_536369105827126569_n.jpg\n",
      "Image: ./train_img\\amenallah\\19756374_1942994705977890_5354592505539705717_n.jpg\n",
      "Image: ./train_img\\amenallah\\20292658_1951473761796651_3915033377466325240_n.jpg\n",
      "Image: ./train_img\\amenallah\\944052_1676458742631489_8494742112819539678_n.jpg\n",
      "Image: ./train_img\\amenallah\\cv_photo.png\n",
      "Image: ./train_img\\amenallah\\download.png\n",
      "Image: ./train_img\\medi\\152747666_2830834127159000_609812728572186872_n.jpg\n",
      "No of Detected Face: 0\n",
      "Unable to align \"./train_img\\medi\\152747666_2830834127159000_609812728572186872_n.jpg\"\n",
      "Image: ./train_img\\medi\\204941193_541127926903264_2832057020508350740_n.jpg\n",
      "Image: ./train_img\\medi\\205151246_1260888774342932_4825014821287305937_n.jpg\n",
      "Image: ./train_img\\medi\\206595885_335817764615759_8566341365283269165_n.jpg\n",
      "Total number of images: 298\n",
      "Number of successfully aligned images: 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#classifier.py\r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "import tensorflow.compat.v1 as tf\r\n",
    "import numpy as np\r\n",
    "import facenet\r\n",
    "import os\r\n",
    "import math\r\n",
    "import pickle\r\n",
    "from sklearn.svm import SVC\r\n",
    "import sys\r\n",
    "\r\n",
    "class training:\r\n",
    "    def __init__(self, datadir, modeldir,classifier_filename):\r\n",
    "        self.datadir = datadir\r\n",
    "        self.modeldir = modeldir\r\n",
    "        self.classifier_filename = classifier_filename\r\n",
    "\r\n",
    "    def main_train(self):\r\n",
    "        with tf.Graph().as_default():\r\n",
    "            with tf.Session() as sess:\r\n",
    "                img_data = facenet.get_dataset(self.datadir)\r\n",
    "                path, label = facenet.get_image_paths_and_labels(img_data)\r\n",
    "                print('Classes: %d' % len(img_data))\r\n",
    "                print('Images: %d' % len(path))\r\n",
    "\r\n",
    "                facenet.load_model(self.modeldir)\r\n",
    "                images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n",
    "                embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n",
    "                phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\r\n",
    "                embedding_size = embeddings.get_shape()[1]\r\n",
    "\r\n",
    "                print('Extracting features of images for model')\r\n",
    "                batch_size = 1000\r\n",
    "                image_size = 160\r\n",
    "                nrof_images = len(path)\r\n",
    "                nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / batch_size))\r\n",
    "                emb_array = np.zeros((nrof_images, embedding_size))\r\n",
    "                for i in range(nrof_batches_per_epoch):\r\n",
    "                    start_index = i * batch_size\r\n",
    "                    end_index = min((i + 1) * batch_size, nrof_images)\r\n",
    "                    paths_batch = path[start_index:end_index]\r\n",
    "                    images = facenet.load_data(paths_batch, False, False, image_size)\r\n",
    "                    feed_dict = {images_placeholder: images, phase_train_placeholder: False}\r\n",
    "                    emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)\r\n",
    "\r\n",
    "                classifier_file_name = os.path.expanduser(self.classifier_filename)\r\n",
    "\r\n",
    "                # Training Started\r\n",
    "                print('Training Started')\r\n",
    "                model = SVC(kernel='linear', probability=True)\r\n",
    "                model.fit(emb_array, label)\r\n",
    "\r\n",
    "                class_names = [cls.name.replace('_', ' ') for cls in img_data]\r\n",
    "\r\n",
    "                # Saving model\r\n",
    "                with open(classifier_file_name, 'wb') as outfile:\r\n",
    "                    pickle.dump((model, class_names), outfile)\r\n",
    "                return classifier_file_name\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#train_main.py \r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "import sys\r\n",
    "from classifier import training\r\n",
    "\r\n",
    "datadir = './pre_img'\r\n",
    "modeldir = './model/20170511-185253.pb'\r\n",
    "classifier_filename = './class/classifier.pkl'\r\n",
    "print (\"Training Start\")\r\n",
    "obj=training(datadir,modeldir,classifier_filename)\r\n",
    "get_file=obj.main_train()\r\n",
    "print('Saved classifier model to file \"%s\"' % get_file)\r\n",
    "print(\"All Done\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Start\n",
      "Classes: 13\n",
      "Images: 291\n",
      "Model filename: ./model/20170511-185253.pb\n",
      "Extracting features of images for model\n",
      "Training Started\n",
      "Saved classifier model to file \"./class/classifier.pkl\"\n",
      "All Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "import tensorflow.compat.v1 as tf\r\n",
    "from scipy import misc\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import facenet\r\n",
    "import detect_face\r\n",
    "import os\r\n",
    "import time\r\n",
    "import pickle\r\n",
    "import sys\r\n",
    "\r\n",
    "\r\n",
    "from PIL import Image\r\n",
    "#scaled.append(np.array(Image.fromarray(cropped[i]).resize((image_size, image_size))))\r\n",
    "\r\n",
    "img_path='./test_img/1604917563754.jpg'\r\n",
    "modeldir = './model/20170511-185253.pb'\r\n",
    "classifier_filename = './class/classifier.pkl'\r\n",
    "npy='./npy'\r\n",
    "train_img=\"./train_img\"\r\n",
    "\r\n",
    "with tf.Graph().as_default():\r\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\r\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\r\n",
    "    with sess.as_default():\r\n",
    "        pnet, rnet, onet = detect_face.create_mtcnn(sess, npy)\r\n",
    "\r\n",
    "        minsize = 20  # minimum size of face\r\n",
    "        threshold = [0.6, 0.7, 0.7]  # three steps's threshold\r\n",
    "        factor = 0.709  # scale factor\r\n",
    "        margin = 44\r\n",
    "        frame_interval = 3\r\n",
    "        batch_size = 1000\r\n",
    "        image_size = 182\r\n",
    "        input_image_size = 160\r\n",
    "        \r\n",
    "        HumanNames = os.listdir(train_img)\r\n",
    "        HumanNames.sort()\r\n",
    "\r\n",
    "        print('Loading feature extraction model')\r\n",
    "        facenet.load_model(modeldir)\r\n",
    "\r\n",
    "        images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n",
    "        embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n",
    "        phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\r\n",
    "        embedding_size = embeddings.get_shape()[1]\r\n",
    "\r\n",
    "\r\n",
    "        classifier_filename_exp = os.path.expanduser(classifier_filename)\r\n",
    "        with open(classifier_filename_exp, 'rb') as infile:\r\n",
    "            (model, class_names) = pickle.load(infile)\r\n",
    "\r\n",
    "        # video_capture = cv2.VideoCapture(\"akshay_mov.mp4\")\r\n",
    "        c = 0\r\n",
    "\r\n",
    "\r\n",
    "        print('Start Recognition!')\r\n",
    "        prevTime = 0\r\n",
    "        # ret, frame = video_capture.read()\r\n",
    "        frame = cv2.imread(img_path,0)\r\n",
    "\r\n",
    "        frame = cv2.resize(frame, (0,0), fx=0.5, fy=0.5)    #resize frame (optional)\r\n",
    "\r\n",
    "        curTime = time.time()+1    # calc fps\r\n",
    "        timeF = frame_interval\r\n",
    "\r\n",
    "        if (c % timeF == 0):\r\n",
    "            find_results = []\r\n",
    "\r\n",
    "            if frame.ndim == 2:\r\n",
    "                frame = facenet.to_rgb(frame)\r\n",
    "            frame = frame[:, :, 0:3]\r\n",
    "            bounding_boxes, _ = detect_face.detect_face(frame, minsize, pnet, rnet, onet, threshold, factor)\r\n",
    "            nrof_faces = bounding_boxes.shape[0]\r\n",
    "            print('Face Detected: %d' % nrof_faces)\r\n",
    "\r\n",
    "            if nrof_faces > 0:\r\n",
    "                det = bounding_boxes[:, 0:4]\r\n",
    "                img_size = np.asarray(frame.shape)[0:2]\r\n",
    "\r\n",
    "                cropped = []\r\n",
    "                scaled = []\r\n",
    "                scaled_reshape = []\r\n",
    "                bb = np.zeros((nrof_faces,4), dtype=np.int32)\r\n",
    "\r\n",
    "                for i in range(nrof_faces):\r\n",
    "                    emb_array = np.zeros((1, embedding_size))\r\n",
    "\r\n",
    "                    bb[i][0] = det[i][0]\r\n",
    "                    bb[i][1] = det[i][1]\r\n",
    "                    bb[i][2] = det[i][2]\r\n",
    "                    bb[i][3] = det[i][3]\r\n",
    "\r\n",
    "                    # inner exception\r\n",
    "                    if bb[i][0] <= 0 or bb[i][1] <= 0 or bb[i][2] >= len(frame[0]) or bb[i][3] >= len(frame):\r\n",
    "                        print('face is too close')\r\n",
    "                        continue\r\n",
    "\r\n",
    "                    cropped.append(frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :])\r\n",
    "                    cropped[i] = facenet.flip(cropped[i], False)\r\n",
    "                    scaled.append(np.array(Image.fromarray(cropped[i]).resize((image_size, image_size))))\r\n",
    "                    scaled[i] = cv2.resize(scaled[i], (input_image_size,input_image_size),\r\n",
    "                                           interpolation=cv2.INTER_CUBIC)\r\n",
    "                    scaled[i] = facenet.prewhiten(scaled[i])\r\n",
    "                    scaled_reshape.append(scaled[i].reshape(-1,input_image_size,input_image_size,3))\r\n",
    "                    feed_dict = {images_placeholder: scaled_reshape[i], phase_train_placeholder: False}\r\n",
    "                    emb_array[0, :] = sess.run(embeddings, feed_dict=feed_dict)\r\n",
    "                    predictions = model.predict_proba(emb_array)\r\n",
    "                    print(predictions)\r\n",
    "                    best_class_indices = np.argmax(predictions, axis=1)\r\n",
    "                    # print(best_class_indices)\r\n",
    "                    best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\r\n",
    "                    print(best_class_probabilities)\r\n",
    "                    cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)    #boxing face\r\n",
    "\r\n",
    "                    #plot result idx under box\r\n",
    "                    text_x = bb[i][0]\r\n",
    "                    text_y = bb[i][3] + 20\r\n",
    "                    print('Result Indices: ', best_class_indices[0])\r\n",
    "                    print(HumanNames)\r\n",
    "                    for H_i in HumanNames:\r\n",
    "                        # print(H_i)\r\n",
    "                        if HumanNames[best_class_indices[0]] == H_i:\r\n",
    "                            result_names = HumanNames[best_class_indices[0]]\r\n",
    "                            cv2.putText(frame, result_names, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\r\n",
    "                                        1, (0, 0, 255), thickness=1, lineType=2)\r\n",
    "            else:\r\n",
    "                print('Unable to align')\r\n",
    "        cv2.imshow('Image', frame)\r\n",
    "\r\n",
    "        if cv2.waitKey(1000000) & 0xFF == ord('q'):\r\n",
    "            sys.exit(\"Thanks\")\r\n",
    "        cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}